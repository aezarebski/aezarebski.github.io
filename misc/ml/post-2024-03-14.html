<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-03-17 Sun 21:42 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AANN 14/03/2024</title>
<meta name="author" content="Alexander E. Zarebski" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="icon" type="image/png" href="../../resources/nicemacs-favicon.png">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/milligram/1.4.1/milligram.css">
<link rel="stylesheet" href="../../microgram.css">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">AANN 14/03/2024</h1>
<p>
<a href="../../index.html">Home</a>
</p>

<p>
<a href="./index.html">Index</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org65df097">Another look at SQR</a>
<ul>
<li><a href="#org9f34004">Overview</a></li>
<li><a href="#org525512c">Model and loss function</a></li>
<li><a href="#orgd1f4b0e">Training</a></li>
<li><a href="#org689efba">Results</a></li>
<li><a href="#org759fa7e">Discussion</a></li>
<li><a href="#sec:helper-functions">Helper functions</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org65df097" class="outline-2">
<h2 id="org65df097">Another look at SQR</h2>
<div class="outline-text-2" id="text-org65df097">

<div id="org1e9a8dd" class="figure">
<p><img src="./example-2024-03-14/cover-image.webp" alt="cover-image.webp" width="400px" />
</p>
</div>
</div>

<div id="outline-container-org9f34004" class="outline-3">
<h3 id="org9f34004">Overview</h3>
<div class="outline-text-3" id="text-org9f34004">
<p>
In this example we will use the <i>simultaneous quantile regression</i>
(SQR) as proposed by <a href="https://doi.org/10.48550/arXiv.1811.00908">Tagasovska and Lopez-Paz (2019)</a> to compute the
quantiles of a prediction. Equation (1) of their paper poses SQR as an
optimisation problem with the following (<a href="https://en.wikipedia.org/wiki/Quantile_regression#Machine_learning_methods_for_quantile_regression">pinball</a>) loss function:
</p>

<p>
\[
\hat{f} = \text{argmin}_{f} \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}_{\tau\sim\text{U}(0,1)} \ell_{\tau}(f(x_i,\tau),y_{i}).
\]
</p>


<p>
We have done this in a <a href="./post-2024-01-25.html">previous post</a>, but here we will focus on one
particular aspect of the training process: the distribution of
\(\tau\) used during training. In the paper, they do not explain the
choice of the uniform distribution of \(\tau\), but do point out that
you want something that minimises over all the quantiles.
</p>

<p>
In practise, I have found this can lead to a model that struggles with
the estimation of the \(95\%\) confidence interval. I suspect this is
because the optimisation process does not see enough values of
\(\tau\) near \(0\) and \(1\) to properly learn the tails. In this
example we look at what happens when you swap the uniform out for a
\(\text{Beta}(1/2, 1/2)\) distribution. There is no particularly good
reason for this, I suspect any symmetric beta distribution with
parameters less than one would suffice, but \(1/2\) is a notable
because of the <a href="https://en.wikipedia.org/wiki/Jeffreys_prior">Jeffreys prior</a>.
</p>

<p>
Building off of the structure from the <a href="./post-2024-01-25.html">previous post</a>, this example
shows that switching to a beta distribution for \(\tau\) leads to a
lower MSE for the point predictions (which isn't as exciting as it
seems) and noticably more conservative intervals.
</p>

<p>
The full script with all the code is <a href="./example-2024-03-14/main.py">here</a>.
</p>
</div>
</div>

<div id="outline-container-org525512c" class="outline-3">
<h3 id="org525512c">Model and loss function</h3>
<div class="outline-text-3" id="text-org525512c">
<p>
See the <a href="./post-2024-01-25.html">previous post</a> for details of the model and loss function.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">class</span> <span style="color: #6434A3;">LocationNB</span>(nn.Module):
    <span style="color: #0000FF;">def</span> <span style="color: #006699;">__init__</span>(<span style="color: #0000FF;">self</span>, m):
        <span style="color: #006FE0;">super</span>(LocationNB, <span style="color: #0000FF;">self</span>).__init__()
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_m</span> = m  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">dataset size: {z_1,...,z_m}</span>
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_num_S</span> = 3  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">number of summary statistics</span>
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_q</span> = 10  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">latent dimension</span>
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_p</span> = 1  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">output dimension</span>

        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_phi</span> = nn.Sequential(
            nn.Linear(<span style="color: #0000FF;">self</span>._num_S + 1, <span style="color: #0000FF;">self</span>._q),
            nn.Sigmoid(),
            nn.Linear(<span style="color: #0000FF;">self</span>._q, <span style="color: #0000FF;">self</span>._q),
            nn.Sigmoid(),
            nn.Linear(<span style="color: #0000FF;">self</span>._q, <span style="color: #0000FF;">self</span>._p),
        )

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">signed_sqrt</span>(<span style="color: #0000FF;">self</span>, x):
        <span style="color: #0000FF;">return</span> torch.sign(x) * torch.sqrt(torch.<span style="color: #006FE0;">abs</span>(x))

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">forward</span>(<span style="color: #0000FF;">self</span>, x, tau):
        <span style="color: #BA36A5;">s0</span> = torch.median(x, dim=1).values
        <span style="color: #BA36A5;">s1</span> = torch.mean(x, dim=1)
        <span style="color: #BA36A5;">s2</span> = torch.mean(x**2, dim=1)
        <span style="color: #BA36A5;">tmp</span> = torch.stack([s0, s1, s2], dim=1)
        <span style="color: #BA36A5;">tmp</span> = <span style="color: #0000FF;">self</span>.signed_sqrt(tmp)
        <span style="color: #BA36A5;">tmp</span> = torch.cat([tmp, tau.unsqueeze(1)], dim=1)
        <span style="color: #0000FF;">return</span> <span style="color: #0000FF;">self</span>._phi(tmp).squeeze(1)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">class</span> <span style="color: #6434A3;">PinballLoss</span>(nn.Module):
    <span style="color: #0000FF;">def</span> <span style="color: #006699;">__init__</span>(<span style="color: #0000FF;">self</span>):
        <span style="color: #006FE0;">super</span>(PinballLoss, <span style="color: #0000FF;">self</span>).__init__()

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">forward</span>(<span style="color: #0000FF;">self</span>, predictions, targets, tau):
        <span style="color: #BA36A5;">err</span> = targets - predictions
        <span style="color: #BA36A5;">loss</span> = torch.where(err &gt;= 0, tau * err, (tau - 1) * err)
        <span style="color: #0000FF;">return</span> torch.mean(loss)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgd1f4b0e" class="outline-3">
<h3 id="orgd1f4b0e">Training</h3>
<div class="outline-text-3" id="text-orgd1f4b0e">
<p>
The training process is pretty standard and was <a href="./post-2024-01-25.html">previously covered</a> so
I won't go into detail beyond pointing out that we run each step of
the training we simulate a new data set and new \(\tau\) from either
the \(\text{Uniform}(0,1)\) or \(\text{Beta}(1/2,1/2)\) distributions.
</p>

<p>
There are a lot of functions used here, they are provided in the
<a href="#sec:helper-functions">section</a> below.
</p>
</div>

<div id="outline-container-org5b098a8" class="outline-4">
<h4 id="org5b098a8">Training loop</h4>
<div class="outline-text-4" id="text-org5b098a8">
<div class="org-src-container">
<pre class="src src-python" id="org7978bc6"><span style="color: #0000FF;">def</span> <span style="color: #006699;">train_model</span>(model, tau_dist, num_steps, train_data_gen):
    <span style="color: #BA36A5;">optimizer</span> = optim.Adam(model.parameters(), lr=1e-3)
    <span style="color: #BA36A5;">loss_function</span> = PinballLoss()
    model.train()
    <span style="color: #BA36A5;">loss_history</span> = []
    <span style="color: #0000FF;">for</span> step <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">range</span>(num_steps):
        <span style="color: #BA36A5;">train_y</span>, <span style="color: #BA36A5;">train_x</span> = train_data_gen()
        <span style="color: #BA36A5;">train_tau</span> = tau_dist.sample(sample_shape=train_y.shape).squeeze(1)
        <span style="color: #BA36A5;">preds</span> = model(train_x, train_tau)
        <span style="color: #BA36A5;">loss</span> = loss_function(preds, train_y, train_tau)
        <span style="color: #BA36A5;">step_loss</span> = loss.item()
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        <span style="color: #0000FF;">if</span> step % 500 == 0:
            <span style="color: #006FE0;">print</span>(f<span style="color: #008000;">"Step </span>{step}<span style="color: #008000;"> loss: </span>{step_loss:.4f}<span style="color: #008000;">"</span>)
            loss_history.append((step, step_loss))

    <span style="color: #0000FF;">return</span> model, loss_history
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org689efba" class="outline-3">
<h3 id="org689efba">Results</h3>
<div class="outline-text-3" id="text-org689efba">
<p>
Figures <a href="#orgb06f01b">1</a> and <a href="#org9eee07e">2</a> show the point estimates across
the two models. Model B (with the beta-distributed tau) has a lower
MSE, although the difference is small.
</p>


<div id="orgb06f01b" class="figure">
<p><img src="./example-2024-03-14/points-a.png" alt="points-a.png" width="400px" />
</p>
<p><span class="figure-number">Figure 1: </span>Point estimates using Model A (uniform tau)</p>
</div>


<div id="org9eee07e" class="figure">
<p><img src="./example-2024-03-14/points-b.png" alt="points-b.png" width="400px" />
</p>
<p><span class="figure-number">Figure 2: </span>Point estimates using Model B (beta tau)</p>
</div>

<p>
Figures <a href="#org04a29cc">3</a> and <a href="#org3aad283">4</a> show the proportion of times
the interval contains the true value across a range of levels. The MSE
is between the requested coverage proportion (on the \(x\)-axis) and
the empirical values (on the \(y\)-axis). Model B has a slightly
higher MSE (suggesting worse calibration) however, does a better job
near the \(95\%\) level which is where most users are most interested.
</p>


<div id="org04a29cc" class="figure">
<p><img src="./example-2024-03-14/coverage-a.png" alt="coverage-a.png" width="400px" />
</p>
<p><span class="figure-number">Figure 3: </span>Coverage of intervals from Model A (uniform tau)</p>
</div>


<div id="org3aad283" class="figure">
<p><img src="./example-2024-03-14/coverage-b.png" alt="coverage-b.png" width="400px" />
</p>
<p><span class="figure-number">Figure 4: </span>Coverage of intervals from Model B (beta tau)</p>
</div>
</div>
</div>

<div id="outline-container-org759fa7e" class="outline-3">
<h3 id="org759fa7e">Discussion</h3>
<div class="outline-text-3" id="text-org759fa7e">
<p>
In this example we have demonstrated how you can encourage a SQR to be
more conservative with the quantiles it produces by sampling the
quantile levels to use in training from a beta distribution rather
than a uniform distribution. This also seems to influence the accuracy
of the point predictions slightly.
</p>

<p>
Since we are usually primarily interested in intervals at the \(95\%\)
level &#x2014; yes, I know this is arbitrary &#x2014; I think switching out for
the beta distribution would be a good idea in practise.
</p>
</div>

<div id="outline-container-orgff7cf8e" class="outline-4">
<h4 id="orgff7cf8e">Thanks</h4>
<div class="outline-text-4" id="text-orgff7cf8e">
<p>
Thanks to <a href="https://www.svi.edu.au/researchers/dr-chun-fung-jackson-kwok/">Jackson Kwok</a>, and <a href="https://www.liamhodgkinson.com/">Liam Hodgkinson</a> for helpful comments on a
draft of this.
</p>
</div>
</div>
</div>

<div id="outline-container-sec:helper-functions" class="outline-3">
<h3 id="sec:helper-functions">Helper functions</h3>
<div class="outline-text-3" id="text-sec:helper-functions">
<div class="org-src-container">
<pre class="src src-python" id="org1dfd4be"><span style="color: #0000FF;">def</span> <span style="color: #006699;">rand_dataset</span>(num_replicates: <span style="color: #006FE0;">int</span>, replicate_size: <span style="color: #006FE0;">int</span>):
    <span style="color: #BA36A5;">mu_i</span> = normal.Normal(torch.tensor([0.0]), torch.tensor([10.0])).sample(
        sample_shape=torch.Size([num_replicates])
    )
    <span style="color: #BA36A5;">x_i</span> = (
        normal.Normal(loc=mu_i, scale=torch.tensor([1.0]))
        .sample(sample_shape=torch.Size([replicate_size]))
        .transpose(0, 1)
        .squeeze(2)
    )
    <span style="color: #BA36A5;">y_i</span> = mu_i.squeeze(1)
    <span style="color: #0000FF;">return</span> y_i, x_i


&lt;&lt;training-loop&gt;&gt;


<span style="color: #0000FF;">def</span> <span style="color: #006699;">record_loss_details</span>(loss_history, loss_csv, loss_png, title_str):
    <span style="color: #BA36A5;">loss_df</span> = pd.DataFrame(loss_history, columns=[<span style="color: #008000;">"step"</span>, <span style="color: #008000;">"loss"</span>])
    loss_df.to_csv(loss_csv)
    <span style="color: #BA36A5;">loss_p9</span> = nn_plot.plot_loss_curve(loss_df, x_var=<span style="color: #008000;">"step"</span>, x_lab=<span style="color: #008000;">""</span>)
    <span style="color: #BA36A5;">loss_p9</span> = (
        loss_p9
        + ggtitle(title_str)
        + theme(plot_title=element_text(size=10, weight=<span style="color: #008000;">"bold"</span>))
    )
    loss_p9.save(loss_png, height=2.9, width=4.1)


<span style="color: #0000FF;">def</span> <span style="color: #006699;">test_coverage</span>(model, xs, ys, alphas, num_replicates):
    <span style="color: #BA36A5;">coverage_results</span> = []
    <span style="color: #0000FF;">for</span> ix <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">range</span>(alphas.shape[0]):
        <span style="color: #BA36A5;">tau_0</span> = (0.5 * alphas[ix]).repeat(num_replicates)
        <span style="color: #BA36A5;">tau_1</span> = 1 - tau_0
        <span style="color: #BA36A5;">est_lower</span> = model(xs, tau_0)
        <span style="color: #BA36A5;">est_upper</span> = model(xs, tau_1)
        <span style="color: #BA36A5;">correct</span> = torch.<span style="color: #006FE0;">sum</span>((est_lower &lt;= ys) &amp; (ys &lt;= est_upper)).item()
        coverage_results.append((alphas[ix].item(), correct, num_replicates))
    <span style="color: #BA36A5;">coverage_df</span> = pd.DataFrame(coverage_results, columns=[<span style="color: #008000;">"alpha"</span>, <span style="color: #008000;">"correct"</span>, <span style="color: #008000;">"total"</span>])
    <span style="color: #BA36A5;">mse_of_coverage_err</span> = (
        ((1 - coverage_df[<span style="color: #008000;">"alpha"</span>]) - (coverage_df[<span style="color: #008000;">"correct"</span>] / coverage_df[<span style="color: #008000;">"total"</span>]))
        ** 2
    ).mean()
    <span style="color: #0000FF;">return</span> coverage_df, mse_of_coverage_err


<span style="color: #0000FF;">def</span> <span style="color: #006699;">test_accuracy</span>(model, xs, ys, num_replicates):
    <span style="color: #BA36A5;">tau_mid</span> = torch.tensor([0.5]).repeat(num_replicates)
    <span style="color: #BA36A5;">est</span> = model(xs, tau_mid)
    <span style="color: #0000FF;">if</span> est.dim() == 2:
        <span style="color: #BA36A5;">est</span> = est.squeeze(1)
    <span style="color: #BA36A5;">point_df</span> = pd.DataFrame(
        <span style="color: #006FE0;">zip</span>(est.tolist(), ys.tolist()), columns=[<span style="color: #008000;">"point_estimate"</span>, <span style="color: #008000;">"truth"</span>]
    )
    <span style="color: #BA36A5;">point_mse</span> = ((point_df[<span style="color: #008000;">"point_estimate"</span>] - point_df[<span style="color: #008000;">"truth"</span>]) ** 2).mean()
    <span style="color: #0000FF;">return</span> point_df, point_mse


<span style="color: #0000FF;">def</span> <span style="color: #006699;">plot_points</span>(point_df, mse, title, filename):
    <span style="color: #BA36A5;">p</span> = (
        ggplot(point_df, aes(x=<span style="color: #008000;">"truth"</span>, y=<span style="color: #008000;">"point_estimate"</span>))
        + geom_point()
        + geom_abline(intercept=0, slope=1, color=<span style="color: #008000;">"red"</span>)
        + labs(x=<span style="color: #008000;">"Truth"</span>, y=<span style="color: #008000;">"Prediction"</span>, title=title, subtitle=f<span style="color: #008000;">"MSE: </span>{mse:.3f}<span style="color: #008000;">"</span>)
        + theme_bw()
        + theme(plot_title=element_text(size=10, weight=<span style="color: #008000;">"bold"</span>))
    )
    p.save(filename, height=2.9, width=4.1)


<span style="color: #0000FF;">def</span> <span style="color: #006699;">plot_coverage</span>(coverage_df, mse_error, title, filename):
    <span style="color: #BA36A5;">p</span> = (
        ggplot(
            coverage_df,
            aes(
                x=<span style="color: #008000;">"1-alpha"</span>, y=<span style="color: #008000;">"correct/total"</span>, shape=<span style="color: #008000;">"((correct/total) &gt;= (1 - alpha))"</span>
            ),
        )
        + geom_point()
        + geom_abline(intercept=0, slope=1, color=<span style="color: #008000;">"red"</span>)
        + scale_x_continuous(limits=(0, 1))
        + scale_y_continuous(limits=(0, 1))
        + labs(
            x=<span style="color: #008000;">"Desired coverage: &#945;"</span>,
            y=<span style="color: #008000;">"Proportion: correct/total"</span>,
            title=title,
            subtitle=f<span style="color: #008000;">"Proportion error MSE: </span>{mse_error:.3f}<span style="color: #008000;">"</span>,
        )
        + theme_bw()
        + theme(plot_title=element_text(size=10, weight=<span style="color: #008000;">"bold"</span>), legend_position=<span style="color: #008000;">"none"</span>)
    )
    p.save(filename, height=2.9, width=4.1)
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Alexander E. Zarebski</p>
<p class="date">Created: 2024-03-17 Sun 21:42</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
