<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-03-28 Thu 10:13 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AANN 28/03/2024</title>
<meta name="author" content="Alexander E. Zarebski" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="icon" type="image/png" href="../../resources/nicemacs-favicon.png">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/milligram/1.4.1/milligram.css">
<link rel="stylesheet" href="../../microgram.css">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">AANN 28/03/2024</h1>
<p>
<a href="../../index.html">Home</a>
</p>

<p>
<a href="./index.html">Index</a>
</p>

<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org3028b41">Orthonormal certificates for epistemic uncertainty</a></li>
<li><a href="#orgca0c8ef">Overview</a></li>
<li><a href="#org7fa7903">Modules</a>
<ul>
<li><a href="#orgb47acea">CNN classifier</a></li>
<li><a href="#orgaeaae0f">Orthonormal certificates</a></li>
</ul>
</li>
<li><a href="#orgc6ba57a">Training and loss function</a></li>
<li><a href="#org0f7d95f">Results</a></li>
<li><a href="#org3a4c908">Discussion</a></li>
</ul>
</div>
</div>

<div id="outline-container-org3028b41" class="outline-2">
<h2 id="org3028b41">Orthonormal certificates for epistemic uncertainty</h2>
<div class="outline-text-2" id="text-org3028b41">

<div id="org8d09a7f" class="figure">
<p><img src="./example-2024-03-28/cover-image.webp" alt="cover-image.webp" width="400px" />
</p>
</div>

<p>
Given neural networks can have questionable ability to extrapolate
beyond the distribution of data they were trained on, we need tools to
detect such situations. In this example we will use the <i>orthonormal
certificates</i> (OCs) as proposed by <a href="https://doi.org/10.48550/arXiv.1811.00908">Tagasovska and Lopez-Paz (2019)</a> to
detect samples that are out-of-distribution from our training data.
</p>
</div>
</div>

<div id="outline-container-orgca0c8ef" class="outline-2">
<h2 id="orgca0c8ef">Overview</h2>
<div class="outline-text-2" id="text-orgca0c8ef">
<p>
As an example, we will consider the same CNN network used for MNIST
classification in this <a href="./post-2024-01-09.html">previous post</a>. However, this time we will only
train on samples corresponding to the digits 0&#x2013;4. The digits 5&#x2013;9
will be considered as out-of-distribution samples. We will use the OCs
to assign scores to samples based on our confidence that they are in
or out of the training distribution.
</p>

<p>
The idea here is that you have a <i>certificate</i>,
\(C_{i}\in\mathbb{R}^{h}\), such that \(C_{i}w = 0\) if \(w\) is a
sample from our training distribution and \(C_{i}w > 0\) if \(w\) is
from some other distribution. However, there are a lot of
distributions that aren't our training distribution, so we consider a
collection of certificates and stack them to make a matrix \(C\). The
goal is then to get a diverse set of certificates (i.e. they are
orthogonal to each other) that also map the training data to zero,
(i.e. they are orthogonal to our training data).
</p>

<p>
The OCs require the samples to be represented as a vector (rather than
an image) so we will the CNN backbone from the classifier to generate
an embedding of the image.<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>
</p>

<p>
The full script with all the code is <a href="./example-2024-03-28/main.py">here</a>.
</p>
</div>
</div>

<div id="outline-container-org7fa7903" class="outline-2">
<h2 id="org7fa7903">Modules</h2>
<div class="outline-text-2" id="text-org7fa7903">
</div>
<div id="outline-container-orgb47acea" class="outline-3">
<h3 id="orgb47acea">CNN classifier</h3>
<div class="outline-text-3" id="text-orgb47acea">
<p>
The network for the classifier is pretty much the same the one used in
<a href="./post-2024-02-22.html">previous posts</a>, however we have added a <code>backbone</code> method so we can
get the output of the CNN without the additional FFN layers. This is
helpful because we will use this as an embedding of the images for our
OCs
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">class</span> <span style="color: #6434A3;">DemoCNN</span>(nn.Module):
    <span style="color: #0000FF;">def</span> <span style="color: #006699;">__init__</span>(<span style="color: #0000FF;">self</span>):
        <span style="color: #006FE0;">super</span>(DemoCNN, <span style="color: #0000FF;">self</span>).__init__()
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_conv1</span> = nn.Conv2d(1, 6, kernel_size=5, padding=2)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_pool1</span> = nn.AvgPool2d(2)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_conv2</span> = nn.Conv2d(6, 16, kernel_size=5, padding=0)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_pool2</span> = nn.AvgPool2d(2)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_fc1</span> = nn.Linear(5 * 5 * 16, 84)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_fc2</span> = nn.Linear(84, 10)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_relu</span> = nn.ReLU()

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">backbone</span>(<span style="color: #0000FF;">self</span>, x):
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._pool1(<span style="color: #0000FF;">self</span>._relu(<span style="color: #0000FF;">self</span>._conv1(x)))
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._pool2(<span style="color: #0000FF;">self</span>._relu(<span style="color: #0000FF;">self</span>._conv2(x)))
        <span style="color: #BA36A5;">x</span> = x.view(-1, 5 * 5 * 16)
        <span style="color: #0000FF;">return</span> x

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">forward</span>(<span style="color: #0000FF;">self</span>, x):
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>.backbone(x)
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._relu(<span style="color: #0000FF;">self</span>._fc1(x))
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._fc2(x)
        <span style="color: #0000FF;">return</span> x
</pre>
</div>
</div>
</div>

<div id="outline-container-orgaeaae0f" class="outline-3">
<h3 id="orgaeaae0f">Orthonormal certificates</h3>
<div class="outline-text-3" id="text-orgaeaae0f">
<p>
Each individual certificate is a row of the <code>_certificates</code> matrix,
\(C\in\mathbb{R}^{h\times k}\), where there are \(k\) certificates and
we are dealing with \(h\)-dimensional observations. The <code>forward</code>
method simply multiples this matrix against the input, to get
\(C^{T}\phi(x)\), where \(\phi(x)\) just means the embedding of some
sample \(x\) into \(\mathbb{R}^{h}\). In our case this is the CNN
backbone of the trained classifier.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">class</span> <span style="color: #6434A3;">OrthonormalCertificates</span>(nn.Module):
    <span style="color: #0000FF;">def</span> <span style="color: #006699;">__init__</span>(<span style="color: #0000FF;">self</span>, dim_in, num_certificates):
        <span style="color: #006FE0;">super</span>(OrthonormalCertificates, <span style="color: #0000FF;">self</span>).__init__()
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_dim_in</span> = dim_in
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_num_certificates</span> = num_certificates
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_certificates</span> = nn.Parameter(
            torch.randn(<span style="color: #0000FF;">self</span>._dim_in, <span style="color: #0000FF;">self</span>._num_certificates)
        )

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">forward</span>(<span style="color: #0000FF;">self</span>, x):
        <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Permute the dimensions of x to vectorise over a batch</span>
        <span style="color: #0000FF;">return</span> torch.matmul(<span style="color: #0000FF;">self</span>._certificates.t(), x.permute((1, 0)))

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">ctc</span>(<span style="color: #0000FF;">self</span>):
        <span style="color: #0000FF;">return</span> torch.matmul(<span style="color: #0000FF;">self</span>._certificates.t(), <span style="color: #0000FF;">self</span>._certificates)

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">get_num_certificates</span>(<span style="color: #0000FF;">self</span>):
        <span style="color: #0000FF;">return</span> <span style="color: #0000FF;">self</span>._num_certificates
</pre>
</div>

<p>
The use of <code>permute</code> in the <code>forward</code> method is to ensure this will
vectorize over a batch of samples. There is a <code>ctc</code> method which
returns \(C^{T}C\) which we will need as part of the regularisation
term in the loss function.
</p>
</div>
</div>
</div>

<div id="outline-container-orgc6ba57a" class="outline-2">
<h2 id="orgc6ba57a">Training and loss function</h2>
<div class="outline-text-2" id="text-orgc6ba57a">
<p>
Training the CNN-based classifier is pretty standard so I won't go
into detail here.
</p>

<p>
To instantiate the OC object we need to specify the dimensionality of
the vectors returned by the CNN backbone (\(5\times5\times16 = 400\))
and the number of certificates.
</p>

<p>
The loss function for the OCs is
</p>

<p>
\[
\frac{1}{n}\sum_{i=1}^{n}\ell_{C}(C^{T}\phi(x_{i}),\mathbf{0}) + \lambda \cdot \| C^{T}C - \mathbf{I}_{k} \|
\]
</p>

<p>
where \(\ell_{C}\) is some arbitrary loss function, (we will use the
MSE below), \(\phi(x_{i})\) is used to indicate the embedding of the
image by the CNN backbone, and \(\lambda\) is a regularisation
constant. In the training loop, we get the CNN embedded images with
the <code>backbone</code> method from the trained <code>DemoCNN</code> instance.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #BA36A5;">num_certificates</span> = 1000
<span style="color: #BA36A5;">oc_model</span> = OrthonormalCertificates(5 * 5 * 16, num_certificates)
<span style="color: #BA36A5;">oc_optimizer</span> = optim.Adam(oc_model.parameters(), lr=1e-3)

oc_model.train()
<span style="color: #BA36A5;">oc_loss_history</span> = []
<span style="color: #0000FF;">for</span> epoch <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">range</span>(oc_training_epochs):
    <span style="color: #BA36A5;">epoch_cumloss</span> = 0
    <span style="color: #0000FF;">for</span> images, label <span style="color: #0000FF;">in</span> train_dataloader:
        <span style="color: #BA36A5;">images</span> = images.unsqueeze(1)
        <span style="color: #BA36A5;">bbs</span> = model.backbone(images)
        <span style="color: #BA36A5;">oc_loss</span> = torch.mean(torch.square(oc_model(bbs)))
        <span style="color: #BA36A5;">reg_loss</span> = torch.mean(
            torch.square(oc_model.ctc() - torch.eye(num_certificates))
        )
        <span style="color: #BA36A5;">loss</span> = oc_loss + 1e-2 * reg_loss
        <span style="color: #BA36A5;">epoch_cumloss</span> += loss.item()
        oc_optimizer.zero_grad()
        loss.backward()
        oc_optimizer.step()

    <span style="color: #006FE0;">print</span>(f<span style="color: #008000;">"Epoch </span>{epoch}<span style="color: #008000;"> loss: </span>{epoch_cumloss}<span style="color: #008000;">"</span>)
    oc_loss_history.append((epoch, epoch_cumloss))
</pre>
</div>
</div>
</div>

<div id="outline-container-org0f7d95f" class="outline-2">
<h2 id="org0f7d95f">Results</h2>
<div class="outline-text-2" id="text-org0f7d95f">
<p>
We wouldn't expect this process to have impacted on the performance of
the CNN classifier, but it is nice to see on the test set it is still
getting \(>99\%\) accuracy.
</p>

<p>
Figure <a href="#org2435bd5">1</a> shows the scores of samples from the test set
based on whether they correspond to digits within the training data
(digits 0&#x2013;4) or those from outside (digits 5&#x2013;9). The ROC AUC<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup>
for these scores is <b>0.88</b>. This ROC AUC isn't as high as what I had
expected given the results in the paper, but it seems like a
reasonable starting point for very little tuning.
</p>


<div id="org2435bd5" class="figure">
<p><img src="./example-2024-03-28/oc_scores.png" alt="oc_scores.png" width="600px" />
</p>
<p><span class="figure-number">Figure 1: </span>The trained orthonormal certificates distinguish between samples from within the training distribution (the digits 0&#x2013;4) and those from outside of the training distribution (5&#x2013;9).</p>
</div>
</div>
</div>

<div id="outline-container-org3a4c908" class="outline-2">
<h2 id="org3a4c908">Discussion</h2>
<div class="outline-text-2" id="text-org3a4c908">
<p>
In this example we have demonstrated how you can use <i>orthonormal
certificates</i> to assign a score to new data related to how similar it
is to the data seen during training. This is important because neural
networks do not always extrapolate well beyond their training data,
and we want to be warned of this situation. It remains to see how a
threshold could be determined for when we are actually in this
situation. Choosing a threshold probably depends heavily on the use
case though.
</p>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
By "backbone" I mean the output of the convolutional layers and by "embedding" I mean a (possibly high-dimensional) vector representation of the image.
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
The area under the curve (AUC) where the curve in question is the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">receiver operating characteristic (ROC) curve</a>.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Alexander E. Zarebski</p>
<p class="date">Created: 2024-03-28 Thu 10:13</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
