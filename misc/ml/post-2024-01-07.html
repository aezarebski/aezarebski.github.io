<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-01-06 Mon 09:32 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>AANN 07/01/2024</title>
<meta name="author" content="Alexander E. Zarebski" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="icon" type="image/png" href="../../resources/nicemacs-favicon.png">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/milligram/1.4.1/milligram.css">
<link rel="stylesheet" href="../../microgram.css">
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">AANN 07/01/2024</h1>
<div class="nav-buttons">
  <a class="button button-outline nav-button" href="./post-2024-01-04.html">Previous</a>
  <a class="button button-outline nav-button" href="../../index.html">Home</a>
  <a class="button button-outline nav-button" href="./index.html">Index</a>
  <a class="button button-outline nav-button" href="./post-2024-01-09.html">Next</a>
</div>

<div id="outline-container-org7b8ac89" class="outline-2">
<h2 id="org7b8ac89">CNN with dropout for MNIST classification</h2>
<div class="outline-text-2" id="text-org7b8ac89">
<p>
In this example we use a simple convolutional neural network with
<i>dropout</i> (during training as introduced by <a href="https://arxiv.org/abs/1207.0580">Hinton et al (2012)</a>) for
handwritten digit recognition. This gets an accuracy on the test
dataset of \(99\%\). Outside of using dropout during training, this is
the same as the <a href="./post-2024-01-04.html">previous CNN example</a>. This improves over the other
method, but only slightly under these conditions. I suspect that since
we are only training for 5 epochs there is not a whole heap of
overfitting happening.
</p>
</div>

<div id="outline-container-org9081b66" class="outline-3">
<h3 id="org9081b66">Loading packages</h3>
<div class="outline-text-3" id="text-org9081b66">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">import</span> torch
<span style="color: #0000FF;">import</span> torch.nn <span style="color: #0000FF;">as</span> nn
<span style="color: #0000FF;">import</span> torch.optim <span style="color: #0000FF;">as</span> optim
<span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np
<span style="color: #0000FF;">import</span> pandas <span style="color: #0000FF;">as</span> pd
<span style="color: #0000FF;">import</span> plotnine <span style="color: #0000FF;">as</span> p9
<span style="color: #0000FF;">from</span> plotnine <span style="color: #0000FF;">import</span> *

<span style="color: #0000FF;">import</span> niceneuron.io <span style="color: #0000FF;">as</span> nn_io
<span style="color: #0000FF;">import</span> niceneuron.data <span style="color: #0000FF;">as</span> nn_data
</pre>
</div>
</div>
</div>

<div id="outline-container-orgd5e812e" class="outline-3">
<h3 id="orgd5e812e">Loading testing and training data</h3>
<div class="outline-text-3" id="text-orgd5e812e">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #BA36A5;">loss_csv</span> = <span style="color: #008000;">"example-2024-01-07-loss.csv"</span>
<span style="color: #BA36A5;">loss_png</span> = <span style="color: #008000;">"example-2024-01-07-loss.png"</span>

<span style="color: #BA36A5;">images_path</span> = <span style="color: #008000;">'data/train-images.idx3-ubyte'</span>
<span style="color: #BA36A5;">labels_path</span> = <span style="color: #008000;">'data/train-labels.idx1-ubyte'</span>
<span style="color: #BA36A5;">images</span> = nn_io.read_idx(images_path)
<span style="color: #BA36A5;">images</span> = images.astype(np.float32)
<span style="color: #BA36A5;">labels</span> = nn_io.read_idx(labels_path)

<span style="color: #BA36A5;">train_dataset</span> = nn_data.MNISTDataset(
    images, labels, flatten=<span style="color: #D0372D;">False</span>, normalise=<span style="color: #D0372D;">True</span>)
<span style="color: #BA36A5;">train_dataloader</span> = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=<span style="color: #D0372D;">True</span>)

<span style="color: #BA36A5;">test_images_path</span> = <span style="color: #008000;">'data/t10k-images.idx3-ubyte'</span>
<span style="color: #BA36A5;">test_labels_path</span> = <span style="color: #008000;">'data/t10k-labels.idx1-ubyte'</span>
<span style="color: #BA36A5;">test_images</span> = nn_io.read_idx(test_images_path)
<span style="color: #BA36A5;">test_images</span> = test_images.astype(np.float32)
<span style="color: #BA36A5;">test_labels</span> = nn_io.read_idx(test_labels_path)
<span style="color: #BA36A5;">test_dataset</span> = nn_data.MNISTDataset(
    test_images, test_labels, flatten=<span style="color: #D0372D;">False</span>, normalise=<span style="color: #D0372D;">True</span>)
<span style="color: #BA36A5;">test_dataloader</span> = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=<span style="color: #D0372D;">False</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf2eecb6" class="outline-3">
<h3 id="orgf2eecb6">Defining the model</h3>
<div class="outline-text-3" id="text-orgf2eecb6">
<p>
Here we define the neural network we will use with the <code>DemoCNNDropout</code>
class.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #0000FF;">class</span> <span style="color: #6434A3;">DemoCNNDropout</span>(nn.Module):
    <span style="color: #0000FF;">def</span> <span style="color: #006699;">__init__</span>(<span style="color: #0000FF;">self</span>, dropout_prob=0.5):
        <span style="color: #006FE0;">super</span>(DemoCNNDropout, <span style="color: #0000FF;">self</span>).__init__()
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_dropout_prob</span> = dropout_prob
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_conv1</span> = nn.Conv2d(1, 6, kernel_size=5, padding=2)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_pool1</span> = nn.AvgPool2d(2)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_conv2</span> = nn.Conv2d(6, 16, kernel_size=5, padding=0)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_pool2</span> = nn.AvgPool2d(2)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_fc1</span> = nn.Linear(5*5*16, 84)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_fc2</span> = nn.Linear(84, 10)
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_relu</span> = nn.ReLU()
        <span style="color: #0000FF;">self</span>.<span style="color: #BA36A5;">_dropout</span> = nn.Dropout(p=<span style="color: #0000FF;">self</span>._dropout_prob)

    <span style="color: #0000FF;">def</span> <span style="color: #006699;">forward</span>(<span style="color: #0000FF;">self</span>, x):
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._pool1(<span style="color: #0000FF;">self</span>._relu(<span style="color: #0000FF;">self</span>._conv1(x)))
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._pool2(<span style="color: #0000FF;">self</span>._relu(<span style="color: #0000FF;">self</span>._conv2(x)))
        <span style="color: #BA36A5;">x</span> = x.view(-1, 5*5*16)
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._relu(<span style="color: #0000FF;">self</span>._fc1(x))
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._dropout(x)
        <span style="color: #BA36A5;">x</span> = <span style="color: #0000FF;">self</span>._fc2(x)
        <span style="color: #0000FF;">return</span> x
</pre>
</div>
</div>
</div>

<div id="outline-container-orgc15ebbe" class="outline-3">
<h3 id="orgc15ebbe">Train the model</h3>
<div class="outline-text-3" id="text-orgc15ebbe">
<p>
Then we need to define a training loop for the model.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #BA36A5;">model</span> = DemoCNNDropout(0.25)

<span style="color: #BA36A5;">loss_fn</span> = nn.CrossEntropyLoss()
<span style="color: #BA36A5;">optimizer</span> = optim.Adam(model.parameters(), lr=1e-3)

model.train()
<span style="color: #BA36A5;">loss_history</span> = []
<span style="color: #0000FF;">for</span> epoch <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">range</span>(5):
    <span style="color: #BA36A5;">epoch_cumloss</span> = 0
    <span style="color: #0000FF;">for</span> images, label <span style="color: #0000FF;">in</span> train_dataloader:
        <span style="color: #BA36A5;">images</span> = images.unsqueeze(1)
        <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Forward pass</span>
        <span style="color: #BA36A5;">logits</span> = model(images)
        <span style="color: #BA36A5;">loss</span> = loss_fn(logits, label)
        <span style="color: #BA36A5;">epoch_cumloss</span> += loss.item()

        <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Backward pass</span>
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    <span style="color: #006FE0;">print</span>(f<span style="color: #008000;">"Epoch </span>{epoch}<span style="color: #008000;"> loss: </span>{epoch_cumloss}<span style="color: #008000;">"</span>)
    loss_history.append((epoch,epoch_cumloss))

<span style="color: #BA36A5;">loss_df</span> = pd.DataFrame(loss_history, columns=[<span style="color: #008000;">'epoch'</span>, <span style="color: #008000;">'loss'</span>])
loss_df.to_csv(loss_csv, index=<span style="color: #D0372D;">False</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-org717c9ab" class="outline-3">
<h3 id="org717c9ab">Test the model</h3>
<div class="outline-text-3" id="text-org717c9ab">
<p>
Then we test it with the following loop. Note that now we have dropout
in the model, it is even more important that we remember to set the
model to evaluation mode rather than training mode.
</p>

<div class="org-src-container">
<pre class="src src-python">model.<span style="color: #006FE0;">eval</span>()
<span style="color: #BA36A5;">correct</span> = 0
<span style="color: #BA36A5;">total</span> = 0
<span style="color: #0000FF;">with</span> torch.no_grad():
    <span style="color: #0000FF;">for</span> images, label <span style="color: #0000FF;">in</span> test_dataloader:
        <span style="color: #BA36A5;">images</span> = images.unsqueeze(1)
        <span style="color: #BA36A5;">logits</span> = model(images)
        <span style="color: #BA36A5;">predicted</span> = torch.argmax(logits, dim=1)
        <span style="color: #BA36A5;">total</span> += label.size(0)
        <span style="color: #BA36A5;">correct</span> += (predicted == label).<span style="color: #006FE0;">sum</span>().item()

<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">print test accuracy</span>
<span style="color: #006FE0;">print</span>(f<span style="color: #008000;">"Test accuracy: </span>{correct / total}<span style="color: #008000;">"</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-org6f7318a" class="outline-3">
<h3 id="org6f7318a">Visualise the results</h3>
<div class="outline-text-3" id="text-org6f7318a">
<p>
Plot the resulting loss values across the epochs.
</p>


<div id="org7733920" class="figure">
<p><img src="./example-2024-01-07-loss.png" alt="example-2024-01-07-loss.png" width="400px" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #BA36A5;">loss_df</span> = pd.read_csv(loss_csv)
<span style="color: #BA36A5;">loss_p9</span> = (
    ggplot(loss_df, aes(x=<span style="color: #008000;">'epoch'</span>, y=<span style="color: #008000;">'loss'</span>)) +
    geom_point() +
    geom_line() +
    theme_bw()
)
loss_p9.save(loss_png, height = 2.9, width = 4.1)
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Alexander E. Zarebski</p>
<p class="date">Created: 2025-01-06 Mon 09:32</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
