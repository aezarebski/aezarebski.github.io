<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-10-08 Thu 17:07 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>aez-notes</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Alex Zarebski" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../css/stylesheet.css" />
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">aez-notes</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org48c957f">Statistics notes</a>
<ul>
<li><a href="#org82fd091">Guassian approximation to posterior</a></li>
<li><a href="#orgf0603a7">Is it statistically significant</a></li>
<li><a href="#org20b8fde">Empirical Distribution Function</a></li>
<li><a href="#org53c6872">The bootstrap</a></li>
<li><a href="#orgebb0f89">MCMC parameter transformation</a></li>
<li><a href="#org142fd7e">Linear regression</a>
<ul>
<li><a href="#org4afc037">Linear regression with <code>lm</code></a></li>
</ul>
</li>
<li><a href="#org1d495fd">Profile likelihood function</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
<a href="../index.html">Home</a>
</p>

<div id="outline-container-org48c957f" class="outline-2">
<h2 id="org48c957f">Statistics notes</h2>
<div class="outline-text-2" id="text-org48c957f">
</div>
<div id="outline-container-org82fd091" class="outline-3">
<h3 id="org82fd091">Guassian approximation to posterior</h3>
<div class="outline-text-3" id="text-org82fd091">
<p>
Consider a posterior distribution where the mode is at \(\theta^{*}\) and the Hessian matrix at this point is \(h''(\theta^{*})\).
If we consider a multivariate Gaussian density, we can see that it will have its mode at the mean, \(\mu\), and, assuming a covariance matrix, \(\Sigma\), the density will have a Hessian of \(-\Sigma^{-1}\) at the mode.
This motivates the Guassian approximation at the mode of the posterior.
</p>
</div>
</div>

<div id="outline-container-orgf0603a7" class="outline-3">
<h3 id="orgf0603a7">Is it statistically significant</h3>
<div class="outline-text-3" id="text-orgf0603a7">
<p>
Here is a table of values for testing whether the a binomial sample differs from fair trials at a significance level of 0.05.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">Trials</th>
<th scope="col" class="org-right">Lower</th>
<th scope="col" class="org-right">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">20</td>
<td class="org-right">6</td>
<td class="org-right">14</td>
</tr>

<tr>
<td class="org-right">40</td>
<td class="org-right">14</td>
<td class="org-right">26</td>
</tr>

<tr>
<td class="org-right">60</td>
<td class="org-right">22</td>
<td class="org-right">38</td>
</tr>

<tr>
<td class="org-right">80</td>
<td class="org-right">31</td>
<td class="org-right">49</td>
</tr>

<tr>
<td class="org-right">100</td>
<td class="org-right">40</td>
<td class="org-right">60</td>
</tr>

<tr>
<td class="org-right">200</td>
<td class="org-right">86</td>
<td class="org-right">114</td>
</tr>

<tr>
<td class="org-right">400</td>
<td class="org-right">180</td>
<td class="org-right">220</td>
</tr>

<tr>
<td class="org-right">600</td>
<td class="org-right">276</td>
<td class="org-right">324</td>
</tr>

<tr>
<td class="org-right">800</td>
<td class="org-right">372</td>
<td class="org-right">428</td>
</tr>

<tr>
<td class="org-right">1000</td>
<td class="org-right">469</td>
<td class="org-right">531</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org20b8fde" class="outline-3">
<h3 id="org20b8fde">Empirical Distribution Function</h3>
<div class="outline-text-3" id="text-org20b8fde">
<p>
Let \(X_1,\dots,X_n\sim F\) IID on \(\mathbb{R}\), then the empirical
distribution function (EDF) is
</p>

<p>
\[
\hat{F}_n(x) = \frac{1}{n}\sum I(X_i \leq x)
\]
</p>

<p>
where \(I\) is the indicator function. Linearity shows 
</p>

<p>
\[
\mathbb{E}\hat{F}_n(x) = F(x)
\]
</p>

<p>
and basic properties of variance and the Bernoulli distribution shows
</p>

<p>
\[
\mathbb{V}\hat{F}_n(x) = \frac{1}{n} F(x) (1 - F(x)).
\]
</p>

<p>
The EDF converges to the CDF in probability (which can be observed from Markov's
inequality.) The DKW inequality bounds this convergence which allows for the
construction of confidence bounds on the EDF. A functional \(T : F \mapsto
\theta\) is called a statistical functional. The <i>plug-in estimator</i> of
\(\theta\) is simply \(T(\hat{F}_n)\).
</p>
</div>
</div>
<div id="outline-container-org53c6872" class="outline-3">
<h3 id="org53c6872">The bootstrap</h3>
<div class="outline-text-3" id="text-org53c6872">
<p>
The bootstrap is a simulation based method to estimate standard errors and
confidence intervals. Consider a statistic \(T\) which is a function of a sample
of \(X_i\sim F\); we want to compute \(\mathbb{V}_F(T)\). The subscript \(F\) is
to indicate that this is with respect to the distribution \(F\). Let \(\hat{F}\)
be the empirical distribution (EDF) of the \(X_i\). The bootstrap uses
\(\mathbb{V}_F(T)\) to approximate \(\mathbb{V}_{\hat{F}}(T)\) which is then
itself estimated via simulation.
</p>

<p>
The simulation typically is just sampling from the EDF with replacement, and we
can always run more simulation to get an arbitrarily good approximation of
\(\mathbb{V}_{\hat{F}}(T)\). The real source of error is how well \(\hat{F}\)
approximate \(F\).
</p>

<p>
In the <i>parametric</i> bootstrap, rather than sampling from the EDF of the data, a
sample is generated from the parametric distribution parameterised by the
estimated parameter value.
</p>
</div>
</div>
<div id="outline-container-orgebb0f89" class="outline-3">
<h3 id="orgebb0f89">MCMC parameter transformation</h3>
<div class="outline-text-3" id="text-orgebb0f89">
<p>
You want to sample \(x\) which has density \(f\) but the MCMC samples are
butting up against the edge of the support. For example, we have \(X\sim
\text{Lognormal}(0,1)\). 
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #3a81c3;">library</span><span style="color: #3a81c3;">(</span>mcmc<span style="color: #3a81c3;">)</span>
<span style="color: #3a81c3;">library</span><span style="color: #3a81c3;">(</span>coda<span style="color: #3a81c3;">)</span>
set.seed<span style="color: #3a81c3;">(</span><span style="color: #4e3163;">1</span><span style="color: #3a81c3;">)</span>

<span style="color: #6c3163; font-weight: bold;">mcmc_samples</span> <span style="color: #ba2f59; font-weight: bold;">&lt;-</span> <span style="color: #3a81c3; font-weight: bold;">function</span><span style="color: #3a81c3;">(</span>obj<span style="color: #3a81c3;">)</span> <span style="color: #3a81c3;">{</span>
    as.mcmc<span style="color: #6c3163;">(</span>metrop<span style="color: #2d9574;">(</span>obj, <span style="color: #4e3163;">1</span>, <span style="color: #4e3163;">10000</span><span style="color: #2d9574;">)</span>$batch<span style="color: #6c3163;">)</span>
<span style="color: #3a81c3;">}</span>

<span style="color: #6c3163; font-weight: bold;">posterior</span> <span style="color: #ba2f59; font-weight: bold;">&lt;-</span> <span style="color: #3a81c3; font-weight: bold;">function</span><span style="color: #3a81c3;">(</span>x<span style="color: #3a81c3;">)</span> <span style="color: #3a81c3;">{</span>
    dlnorm<span style="color: #6c3163;">(</span>x = x, meanlog = <span style="color: #4e3163;">0</span>, sdlog = <span style="color: #4e3163;">1</span>, log = <span style="color: #4e3163;">TRUE</span><span style="color: #6c3163;">)</span>
<span style="color: #3a81c3;">}</span>

x_samples <span style="color: #ba2f59; font-weight: bold;">&lt;-</span> mcmc_samples<span style="color: #3a81c3;">(</span>posterior<span style="color: #3a81c3;">)</span>
</pre>
</div>

<p>
But the sampler keeps jumping into the negative numbers which is a problem. So
you might consider \(Y = log(X)\) as this takes values on the whole real line.
We need to derive the posterior distribution for this, \(g\). Note
</p>

<p>
\[
\left|g(y)dy\right| = \left|f(x)dx\right|,
\]
</p>

<p>
put another way,
</p>

<p>
\[
g(y) = f(x(y)) \left|\frac{dx(y)}{dy}\right|.
\]
</p>

<p>
So, if we let \(x = \exp(y)\), then the Jacobian is just \(\exp(y)\), and when we
take the logarithm to get the log-posterior this becomes just \(y\).
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #6c3163; font-weight: bold;">y_posterior</span> <span style="color: #ba2f59; font-weight: bold;">&lt;-</span> <span style="color: #3a81c3; font-weight: bold;">function</span><span style="color: #3a81c3;">(</span>y<span style="color: #3a81c3;">)</span> <span style="color: #3a81c3;">{</span>
    posterior<span style="color: #6c3163;">(</span>exp<span style="color: #2d9574;">(</span>y<span style="color: #2d9574;">)</span><span style="color: #6c3163;">)</span> + y
<span style="color: #3a81c3;">}</span>

y_samples <span style="color: #ba2f59; font-weight: bold;">&lt;-</span> mcmc_samples<span style="color: #3a81c3;">(</span>y_posterior<span style="color: #3a81c3;">)</span>
</pre>
</div>

<p>
Then a Q-Q plot of the logarithm of the \(X\) samples and the \(Y\) samples
suggests we have gotten this correct. The tails are slightly different because
the second sampler has been able to explore smaller and larger values more
efficiently.
</p>


<div id="org5e0a18a" class="figure">
<p><img src="../images/mcmc-transform-demo.png" alt="mcmc-transform-demo.png" />
</p>
</div>
</div>
</div>

<div id="outline-container-org142fd7e" class="outline-3">
<h3 id="org142fd7e">Linear regression</h3>
<div class="outline-text-3" id="text-org142fd7e">
</div>
<div id="outline-container-org4afc037" class="outline-4">
<h4 id="org4afc037">Linear regression with <code>lm</code></h4>
<div class="outline-text-4" id="text-org4afc037">
<p>
The formulas used to specify a model in R use Wilkinson-Rogers notation.
Consider \(y = \alpha + \beta x + \epsilon\). Often estimators will assume that
the \(\epsilon\) are IID normal random variables. To test whether the
\(\epsilon\) are homoscedastic one might use the <a href="https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test">Breusch-Pagan test</a>. This is
available in R via <code>lmtest::bptest</code>. To test whether the errors follow a normal
distribution, a sensible first pass would be to generate a QQ-plot. But if a
formal method is required there is the <code>stats::shapiro.test</code> function for
normality.
</p>

<p>
Assuming that for the most part the assumptions appear to be valid, we might
dive deeper into the data. The <i>leverage</i> of a datum can be thought of as the
potential to influence parameters and can be calculated with <code>stats::hatvalues</code>.
However, high leverage is not necessarily a bad thing unless it is also an
outlier. One way to measure how plausible a measurement is to have arisen from
the model is by considering its standardised residual, <code>rstandard</code>. 
</p>

<p>
Combining leverage and residual into a single measure, is the goal of the Cook's
distance which is one of the summaries produced by <code>plot.lm</code>. A rule of thumb is
that you want the Cook's distance to be not greater than \(4 N^{-1}\) for a
dataset of size \(N\).
</p>
</div>
</div>
</div>

<div id="outline-container-org1d495fd" class="outline-3">
<h3 id="org1d495fd">Profile likelihood function</h3>
<div class="outline-text-3" id="text-org1d495fd">
<p>
The profile likelihood is a lower dimensional version of the likelihood
function. Consider a likelihood function \(\mathcal{L}(\theta)\) where \(\theta
= (\psi,\lambda)\) where \(\lambda\) are nuisance parameters. The <i>profile
likelihood</i> is
</p>

<p>
\[
\mathcal{L}_{\text{profile}}(\psi) := \max_{\lambda} \mathcal{L}(\psi,\lambda).
\]
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Alex Zarebski</p>
<p class="date">Created: 2020-10-08 Thu 17:07</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
